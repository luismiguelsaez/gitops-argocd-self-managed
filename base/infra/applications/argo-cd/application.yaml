apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: argo-cd
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "4"
spec:
  project: default
  destination:
    namespace: argocd
    server: https://kubernetes.default.svc
  syncPolicy:
    automated:
      prune: false
      selfHeal: true
      allowEmpty: false
    syncOptions:
      - CreateNamespace=true
      - Validate=true
      - RespectIgnoreDifferences=true
    retry:
      limit: 10
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 5m
  source:
    chart: argo-cd
    repoURL: https://argoproj.github.io/argo-helm
    targetRevision: 5.51.6
    helm:
      releaseName: argo-cd
      values: |
        global:
          additionalLabels:
            app: argo-cd
          revisionHistoryLimit: 3
          tolerations:
            - key: karpenter.sh/enabled
              operator: Exists
              effect: NoSchedule
          affinity:
            podAntiAffinity: soft
            nodeAffinity:
              type: hard
              matchExpressions:
                - key: app
                  operator: In
                  values:
                    - argo-cd
          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: topology.kubernetes.io/zone
              whenUnsatisfiable: DoNotSchedule

        configs:
          cm:
            url: https://argocd<path:/eks/cluster/main/ingress#external_domain#AWSCURRENT>
            exec.enabled: true
            admin.enabled: true
            timeout.reconciliation: 60s
            # Enable app-of-apps
            resource.customizations: |
              argoproj.io/Application:
                health.lua: |
                  hs = {}
                  hs.status = "Progressing"
                  hs.message = ""
                  if obj.status ~= nil then
                    if obj.status.health ~= nil then
                      hs.status = obj.status.health.status
                      if obj.status.health.message ~= nil then
                        hs.message = obj.status.health.message
                      end
                    end
                  end
                  hs.message = "Waiting for Application"
                  return hs
            # Application controller ignore settings ( reduces CPU usage significantly )
            resource.ignoreResourceUpdatesEnabled: "true"
            resource.customizations.ignoreResourceUpdates.all: |
                jsonPointers:
                    - /status
            # Old format
            #resource.customizations.health.argoproj.io_Application: |
            #  hs = {}
            #  hs.status = "Progressing"
            #  hs.message = ""
            #  if obj.status ~= nil then
            #    if obj.status.health ~= nil then
            #      hs.status = obj.status.health.status
            #      if obj.status.health.message ~= nil then
            #        hs.message = obj.status.health.message
            #      end
            #    end
            #  end
            #  hs.message = "Waiting for Application"
            #  return hs
          params:
            server.insecure: true
            server.disable.auth: false
            controller.status.processors: 20
            controller.operation.processors: 10
            controller.self.heal.timeout.seconds: 5
            controller.repo.server.timeout.seconds: 60
            applicationsetcontroller.policy: sync
            applicationsetcontroller.enable.progressive.syncs: false
            reposerver.parallelism.limit: 0

        redis:
          enabled: true
          name: redis
          podLabels:
            component: redis
          resources:
            requests:
              cpu: 500m
              memory: 256Mi
            limits:
              cpu: 1000m
              memory: 512Mi
          tolerations:
            - key: karpenter.sh/enabled
              operator: Exists
              effect: NoSchedule
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: app
                        operator: In
                        values:
                          - redis

        redis-ha:
          enabled: false
          persistentVolume:
              enabled: false
              storageClass: ebs
              size: 10Gi
          redis:
            config:
              save: '"900 1"'
          haproxy:
            enabled: true
            hardAntiAffinity: true
            tolerations:
              - key: karpenter.sh/enabled
                operator: Exists
                effect: NoSchedule
            additionalAffinities:
              nodeAffinity:
                requiredDuringSchedulingIgnoredDuringExecution:
                  nodeSelectorTerms:
                    - matchExpressions:
                        - key: app
                          operator: In
                          values:
                            - redis
          tolerations:
            - key: karpenter.sh/enabled
              operator: Exists
              effect: NoSchedule
          topologySpreadConstraints:
            enabled: true
            maxSkew: 1
            topologyKey: topology.kubernetes.io/zone
            whenUnsatisfiable: DoNotSchedule
          hardAntiAffinity: true
          additionalAffinities:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: app
                        operator: In
                        values:
                          - redis

        controller:

          replicas: 2

          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: topology.kubernetes.io/zone
              whenUnsatisfiable: DoNotSchedule

          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: app
                        operator: In
                        values:
                          - argo-cd

        server:

          autoscaling:
            enabled: true
            minReplicas: 2
            maxReplicas: 4

          ingress:
            enabled: true
            ingressClassName: nginx-external
            hosts:
              - argocd<path:/eks/cluster/main/ingress#external_domain#AWSCURRENT>
            paths:
              - /
            pathType: Prefix
            extraPaths: []
            tls: []

          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: topology.kubernetes.io/zone
              whenUnsatisfiable: DoNotSchedule

          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: app
                        operator: In
                        values:
                          - argo-cd

        repoServer:

          serviceAccount:
            create: true
            annotations:
              eks.amazonaws.con/role-arn: <path:/eks/cluster/main/iam/roles#argocd#AWSCURRENT>
            automountServiceAccountToken: true

          # CMP config - BEGIN
          volumes:
            - name: cmp-kustomize-aws-secretsmanager
              configMap:
                name: cmp-kustomize-aws-secretsmanager
            - name: cmp-helm-aws-secretsmanager
              configMap:
                name: cmp-helm-aws-secretsmanager
            - name: cmp-tmp
              emptyDir: {}
          extraContainers:
            - name: cmp-kustomize-aws-secretsmanager
              command:
                - "/var/run/argocd/argocd-cmp-server"
              args:
                - --loglevel
                - debug
                - --logformat
                - json
              image: luismiguelsaez/argocd-cmp-default:v0.0.3
              securityContext:
                runAsNonRoot: true
                runAsUser: 999
                runAsGroup: 999
              volumeMounts:
                - mountPath: /var/run/argocd
                  name: var-files
                - mountPath: /home/argocd/cmp-server/plugins
                  name: plugins
                - mountPath: /home/argocd/cmp-server/config/plugin.yaml
                  subPath: plugin.yaml
                  name: cmp-kustomize-aws-secretsmanager
                - mountPath: /tmp
                  name: cmp-tmp
              env:
                - name: AVP_TYPE
                  value: awssecretsmanager
                - name: HOME
                  value: /tmp
            - name: cmp-helm-aws-secretsmanager
              command:
                - "/var/run/argocd/argocd-cmp-server"
              args:
                - --loglevel
                - debug
                - --logformat
                - json
              image: luismiguelsaez/argocd-cmp-default:v0.0.3
              securityContext:
                runAsNonRoot: true
                runAsUser: 999
                runAsGroup: 999
              volumeMounts:
                - mountPath: /var/run/argocd
                  name: var-files
                - mountPath: /home/argocd/cmp-server/plugins
                  name: plugins
                - mountPath: /home/argocd/cmp-server/config/plugin.yaml
                  subPath: plugin.yaml
                  name: cmp-helm-aws-secretsmanager
                - mountPath: /tmp
                  name: cmp-tmp
              env:
                - name: AVP_TYPE
                  value: awssecretsmanager
                - name: HOME
                  value: /tmp
          # CMP config - END

          autoscaling:
            enabled: true
            minReplicas: 2
            maxReplicas: 5

          podLabels:
            component: repo-server

          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: topology.kubernetes.io/zone
              whenUnsatisfiable: DoNotSchedule

          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: app
                        operator: In
                        values:
                          - argo-cd

        applicationSet:
          replicas: 2

        extraObjects:

          - apiVersion: karpenter.sh/v1alpha5
            kind: Provisioner
            metadata:
              labels:
                app: argo-cd
              name: argo-cd
            spec:
              consolidation:
                enabled: true
              labels:
                app: argo-cd
              providerRef:
                name: bottlerocket-default
              requirements: [
                { key: karpenter.k8s.aws/instance-category, operator: In, values: [t]      },
                { key: kubernetes.io/arch,                  operator: In, values: [arm64]  },
                { key: karpenter.sh/capacity-type,          operator: In, values: [spot]   },
                { key: kubernetes.io/os,                    operator: In, values: [linux]  },
                { key: karpenter.k8s.aws/instance-memory,   operator: Gt, values: ['1024'] }
              ]

          - apiVersion: karpenter.sh/v1alpha5
            kind: Provisioner
            metadata:
              labels:
                app: redis
              name: redis
            spec:
              consolidation:
                enabled: true
              labels:
                app: redis
              providerRef:
                name: bottlerocket-default
              taints:
                - key: karpenter.sh/enabled
                  effect: NoSchedule
              requirements: [
                { key: karpenter.k8s.aws/instance-category, operator: In, values: [t]      },
                { key: kubernetes.io/arch,                  operator: In, values: [arm64]  },
                { key: karpenter.sh/capacity-type,          operator: In, values: [spot]   },
                { key: kubernetes.io/os,                    operator: In, values: [linux]  },
                { key: karpenter.k8s.aws/instance-memory,   operator: Gt, values: ['1024'] }
              ]

          - apiVersion: v1
            kind: ConfigMap
            metadata:
              name: cmp-kustomize-aws-secretsmanager
            data:
              plugin.yaml: |
                apiVersion: argoproj.io/v1alpha1
                kind: ConfigManagementPlugin
                metadata:
                  name: cmp-kustomize-aws-secretsmanager
                spec:
                  version: v1.0
                  init:
                    command: [sh, -c]
                    args:
                      - |
                        find . -type f -name kustomization.yaml
                  generate:
                    command: [sh, -c]
                    args:
                      - |
                        kustomize build . | argocd-vault-plugin generate --verbose-sensitive-output -
                  discover:
                    find:
                      glob: "./**/kustomization.yaml"

          - apiVersion: v1
            kind: ConfigMap
            metadata:
              name: cmp-helm-aws-secretsmanager
            data:
              plugin.yaml: |
                apiVersion: argoproj.io/v1alpha1
                kind: ConfigManagementPlugin
                metadata:
                  name: cmp-helm-aws-secretsmanager
                spec:
                  version: v1.0
                  init:
                    command: [/bin/bash, -c]
                    args:
                      - |
                        helm_repos=$(helm dependencies list | tail -n +2 | awk '{print $3}' | sort | uniq);
                        for repo in $helm_repos; do [ -n "$repo" ] && helm repo add $RANDOM $repo; done
                        rm Chart.lock
                        helm dependency build
                  generate:
                    command: [/bin/bash, -c]
                    args:
                      - |
                        export HELM_INCLUDE_CRDS="--include-crds";
                        export HELM_EXTRA_PARAMS="";
                        if [ -n "$ARGOCD_ENV_HELM_SKIP_CRDS" ]; then
                          export HELM_INCLUDE_CRDS="";
                        fi;
                        if [ -n "$ARGOCD_ENV_HELM_EXTRA_PARAMS" ]; then
                          export HELM_EXTRA_PARAMS="$ARGOCD_ENV_HELM_EXTRA_PARAMS";
                        fi;
                        echo "$ARGOCD_ENV_HELM_VALUES" > values-env.yaml;
                        echo "$ARGOCD_ENV_HELM_VALUES_OVERRIDE" > values-env-override.yaml;
                        helm template $ARGOCD_APP_NAME $HELM_INCLUDE_CRDS $HELM_EXTRA_PARAMS -n $ARGOCD_APP_NAMESPACE -f values-env.yaml -f values-env-override.yaml . |\
                        argocd-vault-plugin generate - --verbose-sensitive-output
                  discover:
                    find:
                      glob: "./**/Chart.yaml"
